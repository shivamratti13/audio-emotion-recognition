 Developed an audio emotion recognition system that classifies audio into 8 emotional categories with 77.59% accuracy using a Random Forest classifier.
Utilized the RAVDESS dataset for training, comprising high-quality emotional speech and song recordings, to build a robust and reliable model.
Designed and deployed a Streamlit app allowing users to upload or record audio for real-time emotion classification.
Utilized Librosa to extract audio features such as MFCCs, ensuring robust and accurate feature representation.
Conducted comprehensive data preprocessing and feature engineering, enhancing model performance and interpretability.

